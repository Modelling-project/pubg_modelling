{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling_summary_nongraph.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import & Custom functions"
      ],
      "metadata": {
        "id": "_hbTXF2ScvQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 함수에서 사용할 라이브러리들입니다."
      ],
      "metadata": {
        "id": "2w8c2oj2ncwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression as linear\n",
        "from sklearn.linear_model import Ridge as ridge\n",
        "from sklearn.linear_model import Lasso as lasso\n",
        "from lightgbm import LGBMRegressor as lgbm\n",
        "from lightgbm import plot_importance\n",
        "import gc"
      ],
      "metadata": {
        "id": "tiUa-LVijii-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "캐글에서 가져온 형변환 최적화 코드입니다."
      ],
      "metadata": {
        "id": "oL5oVGp_nn4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from kaggle\n",
        "def reduce_ram_usage(df) :\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "RJDQI412eqfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NPHNm8hWfmLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Prerpocessing(Processing.py)"
      ],
      "metadata": {
        "id": "IyP4vcKHczpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checkNaN\n",
        "결측치가 있는 행과 결측치 갯수를 출력합니다."
      ],
      "metadata": {
        "id": "zfPiz6qenvox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#결측치 출력\n",
        "def checkNaN(df):\n",
        "    print(\"Missing Value List\")\n",
        "    for col in df.columns:\n",
        "            if df[col].isnull().sum():\n",
        "                print(f\"{col} : {df[col].isnull().sum()} \")"
      ],
      "metadata": {
        "id": "aWwMmtEpfb6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropNaN\n",
        "결측치가 있는 행을 제거합니다."
      ],
      "metadata": {
        "id": "t9pxAEhyn96k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#결측치 제거\n",
        "def dropNaN(df):\n",
        "    print(\"Pre-Processing...\")\n",
        "    for i in df.columns.to_list() :\n",
        "        dpIdx = df[df[i].isnull()==True].index\n",
        "        df.drop(index=dpIdx, inplace=True)\n",
        "    print(f\"{dpIdx} Columns Dropped.\")    \n",
        "    return df"
      ],
      "metadata": {
        "id": "AvA6o_FSnuq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA(생략)"
      ],
      "metadata": {
        "id": "Mau8aekrc8JH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineerng(Engineering.py)"
      ],
      "metadata": {
        "id": "osWWS88wdRVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropOutlier\n",
        "이상치로 판단된 feature를 drop합니다."
      ],
      "metadata": {
        "id": "4kOqCYM0oLEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dropOutlier (df):\n",
        "    #입력받은 인덱스를 제거하는 함수입니다(라인 축약)\n",
        "    def dropIdx(df, idx) :\n",
        "        df.drop(index=idx, inplace=True)\n",
        "        dropIdx.dpIdx_sum +=len(idx)\n",
        "        return df\n",
        "\n",
        "    dropIdx.dpIdx_sum = 0\n",
        "\n",
        "    print(\"Pre-Processing...\")\n",
        "    for i in df.columns.to_list() :\n",
        "        df.drop(index=df[df[i].isnull()==True].index, inplace=True)\n",
        "        \n",
        "    print(\"Droping Outliers...\")\n",
        "    vip_features = [\"assists\",\"boosts\",\"DBNOs\",\"heals\",\"kills\",\"killStreaks\",\"walkDistance\", \"revives\", \"roadKills\", \"vehicleDestroys\"]\n",
        "    \n",
        "    #한 그룹 내에 너무 많은 인원이 있는 경우 (이하 제거).\n",
        "    group = df.groupby('groupId').count()\n",
        "    df = dropIdx(df, df[df.groupId.isin(group[group[\"Id\"]>group[\"Id\"].quantile(0.9999)].index)==True].index) \n",
        "    \n",
        "    #수치형 데이터에서 0.1%의 극값\n",
        "    for col in (vip_features + [\"damageDealt\",\"longestKill\", \"rideDistance\", \"swimDistance\",\"weaponsAcquired\", \"matchDuration\"]):\n",
        "        df = dropIdx(df, df[df[col]>df[col].quantile(0.99999)].index)\n",
        "    \n",
        "    #걸은 거리보다 많은 킬/아이템 사용 등이 있는 경우\n",
        "    for col in vip_features:\n",
        "        df = dropIdx(df, df[df[\"walkDistance\"]<df[col]].index)\n",
        "    \n",
        "    #한 게임의 플레이어보다 많은 처치를 기록한 경우\n",
        "    df = dropIdx(df, df[df.groupby('matchId')['kills'].transform('max')  > df.groupby('matchId')['Id'].transform('count')  ].index)\n",
        "    #차를 타지 않고 로드킬을 올린 경우\n",
        "    df = dropIdx(df, df[(df['rideDistance']==0) & (df['roadKills']>0)  ].index)\n",
        "\n",
        "    #한 서버에 한 팀만 있는 경우, 최대 등수를 조정\n",
        "    df.loc[(df.maxPlace>1)&(df.numGroups==1), \"maxPlace\"] = 1\n",
        "\n",
        "    print(f\"{dropIdx.dpIdx_sum} Columns has deleted!\") \n",
        "\n",
        "    del vip_features, group      \n",
        "    gc.collect()\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "jZHI4rf3pQkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### encodeMatch\n",
        "matchType에 따라 solo, duo, squad, normal(사설,이벤트)로 나눠 onehot-encoding합니다."
      ],
      "metadata": {
        "id": "ZegsXDIlq1C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encodeMatch (df):\n",
        "    print(\"Encoding matchType...\")\n",
        "\n",
        "    mapper = lambda x: 'normal' if ('normal' in x) or ('crash' in x)or ('flare' in x)else x \n",
        "    df[\"matchType\"]=df[\"matchType\"].apply(mapper)\n",
        "\n",
        "    mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) else 'normal' if ('normal' in x) else 'squad' \n",
        "    df[\"matchType\"]=df[\"matchType\"].apply(mapper)\n",
        "\n",
        "    df = pd.concat([df,pd.get_dummies(df[\"matchType\"])], axis=1)\n",
        "\n",
        "    del mapper\n",
        "    return df"
      ],
      "metadata": {
        "id": "uDIfZdLNfH8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### makeCols\n",
        "\n",
        "수치들의 그룹별 통계와 그룹별 통계 등수 칼럼을 추가합니다."
      ],
      "metadata": {
        "id": "Aw9XfHEurP-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeCols (df) :\n",
        "    print(\"Making columns...\")\n",
        "    df[\"killPlace\"] = df.groupby(\"matchId\")[\"kills\"].transform('rank', ascending=False)\n",
        "    #data leakage 없는 killPlace data\n",
        "\n",
        "    stat_feature = [\"assists\",\n",
        "                    \"boosts\",\n",
        "                    \"DBNOs\",\n",
        "                    \"heals\",\n",
        "                    \"kills\",\n",
        "                    \"killStreaks\",\n",
        "                    \"walkDistance\", \n",
        "                    \"revives\", \n",
        "                    \"roadKills\", \n",
        "                    \"vehicleDestroys\",\n",
        "                    \"damageDealt\",\n",
        "                    \"longestKill\", \n",
        "                    \"rideDistance\", \n",
        "                    \"swimDistance\",\n",
        "                    \"weaponsAcquired\"]\n",
        "    stat_list = [\"max\",\"mean\",\"median\",\"min\"]\n",
        "    for col in stat_feature :\n",
        "        for stat in stat_list:\n",
        "            df = pd.concat([df,df.groupby(\"groupId\")[col].transform(stat).rename(f\"{col}_{stat}\")], axis=1) \n",
        "            df = pd.concat([df,df.groupby(\"matchId\")[f\"{col}_{stat}\"].transform('rank', ascending=False).rename(f\"{col}_{stat}Place\")], axis=1)\n",
        "    #group별 column stats, match별 group stats 순위\n",
        "\n",
        "    print(len(stat_feature)*len(stat_list)+1, f\"columns Made! Now {len(df.columns)} column in DF.\")\n",
        "    df = reduce_ram_usage(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-bqma-dyrPfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling&Evaluation (Modeling.py)"
      ],
      "metadata": {
        "id": "wrR817v8dt-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit_model\n",
        "4개의 모델을 학습-예측 후 MAE Score를 출력합니다."
      ],
      "metadata": {
        "id": "jPkWgtO-rz5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model(df) :\n",
        "    features = df.drop([\"Id\",\"groupId\", \"matchType\",\"matchId\", \"numGroups\",\"damageDealt\",\"winPlacePerc\"], axis=1) \n",
        "    target = df[\"winPlacePerc\"]\n",
        "    \n",
        "    train_X, test_X, train_y, test_y = train_test_split(features, target, test_size=0.2, random_state=589)\n",
        "    \n",
        "    for model_func in [linear, ridge, lasso, lgbm]:\n",
        "      print(f\"{model_func} Fitting...\")\n",
        "      model = model_func().fit(train_X, train_y)\n",
        "      pred_y = model.predict(test_X)\n",
        "      print(\"test MAE : \",np.round(mean_absolute_error(pred_y, test_y),6))\n",
        "      pred_y = model.predict(train_X)\n",
        "      print(\"train MAE : \",np.round(mean_absolute_error(pred_y, train_y),6))\n"
      ],
      "metadata": {
        "id": "XEeL0TX9dsDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main.py"
      ],
      "metadata": {
        "id": "r8VfjnNksB0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main() :\n",
        "    print(\"Data loading...\")\n",
        "    train = pd.read_csv(\"./data/train_V2.csv\")\n",
        "    test = pd.read_csv(\"./data/test_V2.csv\")\n",
        "    print(\"Data loaded!\")\n",
        "    \n",
        "    checkNaN(train)\n",
        "    train = dropNaN(train)\n",
        "    \n",
        "    train = dropOutlier(train)\n",
        "    train = encodeMatch(train)\n",
        "    train = makeCols(train)\n",
        "    \n",
        "    train = fit_model(train)\n",
        "\n",
        "if __name__==\"__main__\" :\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "-oB-zQYknYHX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}